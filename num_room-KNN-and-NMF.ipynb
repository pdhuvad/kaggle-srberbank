{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# %load num-rooms.py\n",
    "%reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_org_df=pd.read_csv('train.csv',parse_dates=['timestamp'])\n",
    "#train_org_df.price_doc = train_org_df.price_doc/1000000.\n",
    "macro_org_df=pd.read_csv('macro.csv',parse_dates=['timestamp'])\n",
    "train_df=pd.merge(train_org_df,macro_org_df,how='left',on='timestamp')\n",
    "test_org_df=pd.read_csv('test.csv',parse_dates=['timestamp'])\n",
    "test_df=pd.merge(test_org_df,macro_org_df,on='timestamp',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Points to consider - Test data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[(df.life_sq.isnull()) & (df.num_room.isnull()) & (df.kitch_sq.isnull())].shape\n",
    "df[df.num_room.isnull()].shape\n",
    "tmp1=df[(df.num_room.isnull()) | (df.kitch_sq.isnull())]\n",
    "tmp1[tmp1.full_sq < 10].shape\n",
    "df[df.full_sq < 10].shape\n",
    "tmp2=df[df.notnull()]\n",
    "tmp2.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df[(df.full_sq < 300) & (df.full_sq > 100)]\n",
    "df[df.full_sq < 20].shape\n",
    "df[ (df.full_sq - df.life_sq)  > .9*df.full_sq]\n",
    "df[df.life_sq == df.full_sq].price_doc.mean()\n",
    "df=train_org_df[['full_sq','life_sq','kitch_sq','num_room','sub_area','floor', 'price_doc']]\n",
    "tmp=train_df[train_df.sub_area=='Nagornoe']\n",
    "#Do not include sub area ,less important.. \n",
    "tmp.num_room.hist(bins=10)\n",
    "plt.show()\n",
    "tmp=train_df[train_df.sub_area=='Solncevo']\n",
    "tmp.num_room.hist(bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN imputation game plan\n",
    "(a) for 7200 entries, we have life_sq but not kitch_sq\n",
    "\n",
    " (b) for 2200 enteries, we have neither life_sq or kitch_sq \n",
    "\n",
    " odd values of full_sq and life_sq are equally distributed over train, test and null values of num_rooms\n",
    "\n",
    " KNN1- use full_sq, life_sq, sub_are, price_doc to impute (a) above\n",
    "\n",
    "KNN2 - use only full_sq,sub_area and price_doc to impute (b)\n",
    "\n",
    "\n",
    " No num_room null values in test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN1-imputation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "now consider following features are sufficient enough to predict num_rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now lets consider only rows with 'full_sq','life_sq','floor','sub_area','price_doc' not null at all to predict num_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn1_impute(train_org_df):\n",
    "    #df=train_org_df[['full_sq','life_sq','num_room', 'price_doc']]\n",
    "    df=train_org_df[['full_sq','life_sq','num_room','sub_area', 'price_doc']]\n",
    "    df=pd.get_dummies(df)\n",
    "    #seperate test and train for KNN1 for which life_sq is never null\n",
    "    train_df = df[(df.num_room.notnull()) & (df.life_sq.notnull())]\n",
    "    train_X_df=train_df.drop('num_room',1)\n",
    "    train_y_df=train_df.num_room\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(train_X_df,train_y_df,test_size=.2,random_state=16)\n",
    "    hidden_df=df[df.num_room.isnull() & (df.life_sq.notnull())]\n",
    "    hidden_X_df=hidden_df.drop('num_room',1)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn=KNeighborsClassifier()\n",
    "    knn.fit(train_X,train_y)\n",
    "\n",
    "    test_predict_y=knn.predict(test_X)\n",
    "    knn.score(test_X,test_y)\n",
    "    hidden_X_df['num_room']=knn.predict(hidden_X_df)\n",
    "\n",
    "    tmp1=hidden_X_df.num_room\n",
    "    tmp1.shape\n",
    "    imputed_train_df=train_org_df.copy()\n",
    "    imputed_train_df.update(tmp1,raise_conflict=True)\n",
    "    return imputed_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn1_train_df=knn1_impute(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN1 - completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN2-imputation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "now consider following features are sufficient enough to predict num_rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now lets consider only 'full_sq','sub_area','price_doc' not null at all to predict num_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn2_impute(train_org_df):\n",
    "    df=train_org_df[['full_sq','life_sq','kitch_sq','num_room','sub_area', 'price_doc']]\n",
    "    df=pd.get_dummies(df)\n",
    "\n",
    "    #seperate test and train for KNN1 for which life_sq is never null\n",
    "\n",
    "    train_df = df[(df.num_room.notnull())]\n",
    "    train_X_df=train_df.drop(['num_room','life_sq','kitch_sq'],1)\n",
    "    train_y_df=train_df.num_room\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(train_X_df,train_y_df,test_size=.2,random_state=16)\n",
    "    hidden_df=df[df.num_room.isnull() & (df.life_sq.isnull()) & (df.kitch_sq.isnull())]\n",
    "    hidden_X_df=hidden_df.drop(['num_room','life_sq','kitch_sq'],1)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn=KNeighborsClassifier()\n",
    "    knn.fit(train_X,train_y)\n",
    "\n",
    "    test_predict_y=knn.predict(test_X)\n",
    "    knn.score(test_X,test_y)\n",
    "    hidden_X_df['num_room']=knn.predict(hidden_X_df)\n",
    "\n",
    "    tmp1=hidden_X_df.num_room\n",
    "    imputed_train_df=train_org_df.copy()\n",
    "    imputed_train_df.update(tmp1,raise_conflict=True)\n",
    "    return imputed_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn2_train_df=knn2_impute(knn1_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=knn2_train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN2- completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def room_rent_drop(df):\n",
    "    room_rent_df = df\n",
    "    room_rent_df.ix[room_rent_df['num_room']== 1,['rent_price_4+room_bus', 'rent_price_3room_bus', 'rent_price_2room_bus',  'rent_price_3room_eco', 'rent_price_2room_eco', ]]=0\n",
    "    room_rent_df.ix[room_rent_df['num_room']== 2,['rent_price_4+room_bus', 'rent_price_3room_bus',  'rent_price_1room_bus', 'rent_price_3room_eco',  'rent_price_1room_eco']]=0\n",
    "    room_rent_df.ix[room_rent_df['num_room']== 3,['rent_price_4+room_bus',  'rent_price_2room_bus', 'rent_price_1room_bus', 'rent_price_2room_eco', 'rent_price_1room_eco']]=0\n",
    "    room_rent_df.ix[room_rent_df['num_room'] >= 4,[ 'rent_price_3room_bus', 'rent_price_2room_bus', 'rent_price_1room_bus', 'rent_price_3room_eco', 'rent_price_2room_eco', 'rent_price_1room_eco']]=0\n",
    "    \n",
    "    return room_rent_df\n",
    "def room_rent_avgs_only(df):\n",
    "    train_df=room_rent_drop(df)\n",
    "    tmp1 =train_df[train_df.num_room.isnull()]\n",
    "    tmp1['rent_eco_all']=0\n",
    "    tmp1.ix[tmp1.num_room.isnull(),'rent_eco_all'] = tmp1[['rent_price_2room_eco', 'rent_price_1room_eco', 'rent_price_3room_eco']].mean(axis=1)\n",
    "    tmp2 =train_df[train_df.num_room.notnull()]\n",
    "    tmp2['rent_eco_all']=tmp2[['rent_price_2room_eco', 'rent_price_1room_eco', 'rent_price_3room_eco']].sum(axis=1)\n",
    "    train_df =pd.concat([tmp1,tmp2],ignore_index=True)\n",
    "    tmp3 =train_df[train_df.num_room.isnull()]\n",
    "    tmp3['rent_bus_all']=0\n",
    "    tmp3.ix[tmp3.num_room.isnull(),'rent_eco_all'] = tmp3[['rent_price_2room_bus', 'rent_price_1room_bus', 'rent_price_3room_bus','rent_price_4+room_bus']].mean(axis=1)\n",
    "    tmp4 =train_df[train_df.num_room.notnull()]\n",
    "    tmp4['rent_bus_all']=tmp4[['rent_price_2room_bus', 'rent_price_1room_bus', 'rent_price_3room_bus','rent_price_4+room_bus']].sum(axis=1)\n",
    "    tmp4.tail()\n",
    "    train_df =pd.concat([tmp3,tmp4],ignore_index=True)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking care of numeric data using NMF .....\n",
      "Doing NMF .....\n",
      "Replacing nan with NMF values.....\n",
      "Taking care of build year .....\n",
      "starting model building using random forest.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  9.5min finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import gc\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "train_df=room_rent_avgs_only(train_df)\n",
    "test_df=room_rent_avgs_only(test_df)\n",
    "tmp10 =train_df.copy()\n",
    "tmp10.ix[tmp10.num_room>=4,'rent_eco_all']= tmp10['rent_bus_all']\n",
    "train_df = tmp10.copy()\n",
    "\n",
    "#rng = np.random.RandomState(0)\n",
    "#tmp_df=train_df.copy()\n",
    "y_train=train_df['price_doc'].as_matrix()\n",
    "\n",
    "#new\n",
    "features=train_df.columns\n",
    "use_fea=list(features[2:15])\n",
    "# expand\n",
    "use_fea.append('railroad_km')\n",
    "use_fea.append('cafe_count_5000')\n",
    "use_fea.append('cafe_count_2000')\n",
    "use_fea.append('metro_km_avto')\n",
    "use_fea.append('metro_min_walk')\n",
    "use_fea.append('bus_terminal_avto_km')\n",
    "use_fea.append('big_market_km')\n",
    "use_fea.append('oil_urals')\n",
    "use_fea.append('mortgage_rate')\n",
    "use_fea.append('unemployment')\n",
    "use_fea.append('rent_bus_all')\n",
    "use_fea.append('rent_eco_all')\n",
    "\n",
    "Test_Combined = test_df.copy()\n",
    "Train_Combined = train_df.copy()\n",
    "\n",
    "train_fea=Train_Combined.columns\n",
    "test_fea=Test_Combined.columns\n",
    "\n",
    "drop_train_fea=[i for i in train_fea if i not in use_fea]\n",
    "Train_Data=Train_Combined.drop(drop_train_fea,axis=1)\n",
    "\n",
    "drop_test_fea=[i for i in test_fea if i not in use_fea]\n",
    "Test_Data=Test_Combined.drop(drop_test_fea, axis=1)\n",
    "\n",
    "\n",
    "#identify problemetic data\n",
    "\n",
    "\n",
    "\n",
    "#S_life_sq1=Train_Data['life_sq'].isnull()\n",
    "#S_life_sq2=Train_Data['life_sq'] < 5\n",
    "#S_life_sq=S_life_sq1 | S_life_sq2\n",
    "#\n",
    "#\n",
    "#S_maxfloor=Train_Data['max_floor'].isnull()\n",
    "#S_material=Train_Data['material'].isnull()\n",
    "#S_build_year=Train_Data['build_year'].isnull()\n",
    "#S_num_room=Train_Data['num_room'].isnull()\n",
    "#S_kitch_sq=Train_Data['kitch_sq'].isnull()\n",
    "#S_state=Train_Data['state'].isnull()\n",
    "\n",
    "#Train_Data1= Train_Data.copy(deep=True)\n",
    "#Test_Data1= Test_Data.copy(deep=True)\n",
    "\n",
    "print('Taking care of numeric data using NMF .....')  \n",
    "drop_category_fea=['product_type', 'sub_area', 'build_year']\n",
    "Train_Data1=Train_Data.drop(drop_category_fea, axis=1)\n",
    "Test_Data1=Test_Data.drop(drop_category_fea, axis=1)\n",
    "gc.collect()\n",
    "\n",
    "#Train_Data1.fillna(Train_Data1.mean())\n",
    "#Test_Data1.fillna(Test_Data1.mean())\n",
    "\n",
    "numeric_fea=[]\n",
    "for fea in use_fea:\n",
    "    if fea not in drop_category_fea:\n",
    "      numeric_fea.append(fea)\n",
    "      Train_Data1[fea].fillna(Train_Data1[fea].median(), inplace=True)\n",
    "      Test_Data1[fea].fillna(Test_Data1[fea].median(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#dropped_df=tmp_df.drop(['modern_education_share','price_doc','timestamp','id'],axis=1)\n",
    "#dropped_test_df=testm_df.drop(['modern_education_share','timestamp','id'],axis=1)\n",
    "Data_FULLn_arr=[Train_Data1, Test_Data1]\n",
    "DATA_Fulln=pd.concat(Data_FULLn_arr)\n",
    "gc.collect()\n",
    "\n",
    "X_Matrix=DATA_Fulln.as_matrix()\n",
    "print('Doing NMF .....')       \n",
    "\n",
    "nmf_model = NMF(n_components=5, random_state=1,\n",
    "          alpha=.000001, l1_ratio=.5).fit(X_Matrix)\n",
    "\n",
    "H=nmf_model.components_\n",
    "W=nmf_model.transform(X_Matrix)\n",
    "X_transform=np.dot(W, H)\n",
    "\n",
    "\n",
    "\n",
    "Data_FULL_arr=[Train_Data, Test_Data]\n",
    "DATA_Full=pd.concat(Data_FULL_arr)\n",
    "gc.collect()\n",
    "\n",
    "print('Replacing nan with NMF values.....') \n",
    "\n",
    "for indx,fea in enumerate(numeric_fea):\n",
    "        A1=pd.isnull(Train_Data[fea]).as_matrix()\n",
    "        A2=pd.isnull(Test_Data[fea]).as_matrix()\n",
    "        A=np.concatenate((A1, A2), axis=0)\n",
    "        A3=A* X_transform[:,indx]\n",
    "        X_Matrix[:,indx]=A3 + X_Matrix[:,indx]\n",
    "        DATA_Full[fea]=X_Matrix[:,indx]\n",
    "        \n",
    "        \n",
    "print('Taking care of build year .....')        \n",
    "DATA_Full['build_year'].fillna(DATA_Full['build_year'].median(), inplace=True)\n",
    "  \n",
    "DATA_Full.loc[DATA_Full['build_year'] > 2020, 'build_year'] = 2000  \n",
    "DATA_Full.loc[DATA_Full['build_year'] <1850, 'build_year'] = 1900 \n",
    "\n",
    "DATA_Full_dummy=pd.get_dummies(DATA_Full)\n",
    "\n",
    "X_full = DATA_Full_dummy.as_matrix()\n",
    "X_full=np.nan_to_num(X_full)\n",
    "\n",
    "#X_full = preprocessing.scale(X_full)\n",
    "\n",
    "\n",
    "X_train=X_full[0:len(y_train), :]\n",
    "X_test=X_full[len(y_train): , :]\n",
    "\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "print('starting model building using random forest.....')\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=500, verbose=1)\n",
    "estimator.fit(X_train, y_train)\n",
    "predicted_y= estimator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "#print(\"Score with the entire dataset = %.2f\" % score)\n",
    "\n",
    "\n",
    "AA=[list(Test_Combined['id']), predicted_y]\n",
    "f=open('submit5.csv', 'w')\n",
    "f.write('id,price_doc\\n')\n",
    "for i,a in enumerate(AA[0]):\n",
    "    f.write('{0},{1}\\n'.format(AA[0][i], AA[1][i]))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
